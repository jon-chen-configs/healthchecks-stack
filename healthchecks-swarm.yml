services:
  healthchecks:
    image: lscr.io/linuxserver/healthchecks
    env_file: ["${ENV_DIR:-swarm-envs}/swarm/healthchecks-stack/healthchecks.env"]
    deploy:
      replicas: 1
      placement:
        # Docker (20.10.3) on Synology bug where env vars from env_file 
        # not set on container.
        # constraints: [node.platform.arch != aarch64]
        constraints:
          - node.platform.arch != aarch64
          - node.hostname != ${NAS_HOSTNAME}
      resources:
        limits:
          memory: 512M
      labels:
        - traefik.enable=true
        - traefik.docker.network=traefik-net
        - traefik.http.routers.healthcheck.rule=Host(`healthchecks.cynicsoft.net`)
        - traefik.http.routers.healthcheck.entrypoints=https
        - traefik.http.routers.healthcheck.middlewares=internal-whitelist
        - traefik.http.services.healthcheck.loadbalancer.server.port=8000
        - homepage.name=Healthchecks
        - homepage.group=Network
        - homepage.icon=https://raw.githubusercontent.com/modem7/MiscAssets/master/Icons/Dashboard-Icons/healthchecks.png
        - homepage.href=https://healthchecks.cynicsoft.net/
        - homepage.description=Cron job monitoring
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - healthchecks_data:/config
    networks:
      - default
      - traefik-net

  smtp:
    image: namshi/smtp:latest
    env_file: ["${ENV_DIR:-swarm-envs}/swarm/shared/namshi_smtp.env"]
    deploy:
      replicas: 1
      placement:
        # Docker (20.10.3) on Synology bug where env vars from env_file 
        # not set on container.
        # constraints: [node.platform.arch != aarch64]
        constraints:
          - node.platform.arch != aarch64
          - node.hostname != ${NAS_HOSTNAME}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - default

  healthchecks-backup-db-job:
    image: efrecon/sqlite-backup:latest
    user: "0:0"
    deploy:
      mode: replicated
      replicas: 0
      placement:
        constraints: [node.platform.arch != aarch64]
      restart_policy:
        condition: none
      labels:
        - swarm.cronjob.enable=true
        - swarm.cronjob.schedule=@daily
    networks:
      - default
    # https://hub.docker.com/r/efrecon/sqlite-backup
    entrypoint: >-
      sh -c 'LOG=/logs/healthchecks-backup-db-job.log;
      date 2>&1 | tee $$LOG;
      wget -SO - http://tasks.healthchecks:8000/ping/ec476fc6-6567-4019-99a7-d10f7faed654/start 2>&1 | tee -a $$LOG;
      echo "backing up db..." 2>&1 | tee -a $$LOG;
      /usr/local/bin/backup.sh -f /data/hc.sqlite -k 2 -d /backups/data/sqlite -n "healthchecks_backup_%Y%m%d-%H%M%S.sql.gz" 2>&1 | tee -a $$LOG;
      wget -SO - http://tasks.healthchecks:8000/ping/ec476fc6-6567-4019-99a7-d10f7faed654/$$? 2>&1 | tee -a $$LOG'
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - healthchecks_data:/data
      - healthchecks-stack_logs:/logs
      - backups:/backups


volumes:
  healthchecks_data:
    driver_opts:
      type: nfs
      o: addr=${NAS_HOST},nolock,noresvport,vers=2
      device: :${DATADIR}/healthchecks-stack/healthchecks
  healthchecks-stack_logs:
    driver_opts:
      type: nfs
      o: addr=${NAS_HOST},nolock,noresvport,vers=2
      device: :${DATADIR}/healthchecks-stack/logs
  backups:
    driver_opts:
      type: nfs
      o: addr=${NAS_HOST},nolock,noresvport,vers=2
      device: :/volume4/docker/backups


networks:
  default:
    name: healthchecks-swarm_default
    driver: overlay
    attachable: true
  traefik-net:
    external: true